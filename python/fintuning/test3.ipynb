{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/chan6502/Library/Python/3.11/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# CSV 파일에서 커피 데이터 읽어오기\n",
    "coffee_data = pd.read_csv('starbucks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 OPENAI_SECRET_KEY 환경 변수 읽기 # ChatGPT API 키 설정\n",
    "openai.api_key = os.getenv(\"OPENAI_SECRET_KEY\")\n",
    "\n",
    "# ChatGPT로 응답 생성\n",
    "def generate_response(query):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=query,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_coffee():\n",
    "    query = \"I would like a coffee recommendation\"\n",
    "    response = generate_response(query)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_coffee(coffee_name):\n",
    "    # 커피 이름을 이용하여 상세 정보를 가져오는 로직 추가\n",
    "    coffee_info = coffee_data[coffee_data['name'] == coffee_name]\n",
    "    \n",
    "    if not coffee_info.empty:\n",
    "        description = coffee_info['content'].values[0]\n",
    "        return description\n",
    "    else:\n",
    "        return \"I'm sorry, I don't have information about that coffee.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def provide_additional_info(coffee_name):\n",
    "    # 커피 이름을 이용하여 추가 정보를 가져오는 로직 추가\n",
    "    coffee_info = coffee_data[coffee_data['name'] == coffee_name]\n",
    "    \n",
    "    if not coffee_info.empty:\n",
    "        additional_info = f\"Caffeine: {coffee_info['detail.caffeine'].values[0]} mg\\nKcal: {coffee_info['detail.kcal'].values[0]}\\nSaturated Fat: {coffee_info['detail.sat_FAT'].values[0]} g\\nSodium: {coffee_info['detail.sodium'].values[0]} mg\\nSugars: {coffee_info['detail.sugars'].values[0]} g\"\n",
    "        return additional_info\n",
    "    else:\n",
    "        return \"I'm sorry, I don't have information about that coffee.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(query):\n",
    "    if \"recommend coffee\" in query:\n",
    "        response = recommend_coffee()\n",
    "    elif \"describe\" in query:\n",
    "        coffee_name = \"coffee\"  # 여기에 커피 이름을 추출하는 로직 추가\n",
    "        response = describe_coffee(coffee_name)\n",
    "    elif \"additional info\" in query:\n",
    "        coffee_name = \"coffee\"  # 여기에 커피 이름을 추출하는 로직 추가\n",
    "        response = provide_additional_info(coffee_name)\n",
    "    else:\n",
    "        response = generate_response(query)\n",
    "    \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# 커피 이름 추출을 위한 Sentence Transformer 모델 초기화\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# 사용자 질문에서 커피 이름 추출\n",
    "def extract_coffee_name(query):\n",
    "    # 커피 데이터에서 커피 이름 목록 추출\n",
    "    coffee_names = coffee_data['name'].tolist()\n",
    "    \n",
    "    # 입력 질문을 Sentence Transformer 모델로 임베딩\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # 모든 커피 이름에 대한 임베딩 생성\n",
    "    coffee_name_embeddings = model.encode(coffee_names, convert_to_tensor=True)\n",
    "\n",
    "    # 사용자 질문과 모든 커피 이름 간의 코사인 유사도 계산\n",
    "    similarities = util.pytorch_cos_sim(query_embedding, coffee_name_embeddings)[0]\n",
    "\n",
    "    # 유사도가 가장 높은 커피 이름 추출\n",
    "    closest_coffee_name = coffee_names[similarities.argmax()]\n",
    "\n",
    "    return closest_coffee_name\n",
    "\n",
    "# 커피 이름 추출\n",
    "coffee_name = extract_coffee_name(query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
